# Predicing Malware using Neural Networks
A Project by: Tung Phung

<p align="center">
  <img width="320" height="260" src="malware-cybersecurity-skull-crossbone-100735067-large.jpg">
</p>

## Goals:
Typically, malware (viruses, worms, and trojans) detection is done by cybersecurity professionals in an analog, but still digital manner. By using a suite of tools available to most programmers, they meticulously pore over the Portable Executable's (PE) - ie. a .exe or .dll - method of execution and its attack vectors. This can be done by analyzing the PE's header, strings, hexcode, or if possible its decompiled binary. Following this, the security researcher comes up with a list of "fingerprints" or distinct markers of the virus, which could range from its attack vector to the overall structure of the binary. 

This leads to malware software which attempts to identify this malware through specific, generic, and heuristic detection. Specific being finding the exact same piece of malware which has already been previously detected, generic being similar classes of malware, oftentimes where something very miniscule has been changed in an attempt to evade the specific filters and then heuristic detection where malware detection looks for specific activities, such as unauthorized port activity or file structures similar to known malware. In this sense, detection is only as good as the capability of the cybersecurity researcher. This process can not be replaced,but can certainly be augmented by machine learning approaches, where the fingerprints of malware binaries can be picked out. We expect many downsides, especially in the detection of false-positives and the false detection of normal system files. Our model hopes to achieve as high an accuracy score as possible.


## Methods:
Using python and keras as the path to the tensorflow library, we can assemble a convolutional neural network that uses "images" of the potential malware files to identify them.

## Executive Summary:




EXAMPLE - Initially, our approached stemmed around the assumption Twitter stores geo-location data on its user's tweets. However, Twitter requires users to opt into this geo-location system. This leads to the vast majority of tweets having no geo-location tag. However, users still may have home location data that they specify in their profile, which is more apt to be associated with their hometown or their home location, but not the location where they are currently "tweeting" from. This gave us a path to possibly follow. Most other mainstream social media systems such as Facebook, Instagram are not easily scrapable or have API's that are unconducive to the data required in this project.

In finding TwitterScraper by taspinar, which is a rudimentary web-scraping system, we were able to input a search query with our own defined GPS coordinates and a specified radius. According to Twitter's Developer, a search with a GPS and radius will try to first get geo-location but will default a home-location if it falls inside the search area. This was a possible entry-point to analysis. By letting Twitter's backend do the area search and handle geo-locations, we could focus on other things. This was the main part of our approach. Knowing this, we could take any GPS coordinate as a centroid and create a rudimentary grid search around this point in a patterned manner. We could then take the GPS coordinates and define a basic radius (we used 7.5km) to search around.

However, in order to understand and label high areas of higher tweet distress, we needed an NLP algorithm to identify and label so we could have a quantized value. From our experiments, we found a Density-Based clustering algorithm and a Counter-Vectorizer with stop-words and 1,2 ngrams along with our own non-NLP determined "danger" words set was adequate to highlight the areas where tweets were more focused on danger and requiring assistance. Due to time constraints, we were able to only account and train our model off hurricanes, with further time, we would increase the available range of disasters the model could account for. 

As such, the workflow for an emergency response person would be as such. They would input a word such as "hurricane" into our engine, which would scrape for the most current tweets in a user-defined time-frame (probably within the last couple days). They would also input a series of GPS coordinates related to the area of interest. The system creates a grid system around this centroid GPS point and would then scrape Twitter for the time-frame and assess each of the points of intersection on the grid for danger. It would then output a map which labels this danger in a user interpretable manner (See examples 1-3)

## Conclusions and Recommendations:




EXAMPLE While our results make intuitive sense, we were not able with the time constrictions able to correlate the actual Twitter data with the actual on-the-ground response to correlate it to real life. Since our model was unsupervised, it was appropriate, but grounding it in real-ground response with buy-in from emergency workers and stakeholders would allow us to improve our model and see where there were positive or negative responses. This would be a huge stepping stone in the model's legitimacy. We would also seek to not only improve it for a wider range of disasters but also generate Word2Vec models to allow for users to put in a basic word such as "hurricane" and the system would generate a series of related words that it would also search for to increase coverage of the search terms. We would also use Word2Vec to generate danger words based on danger-positive tweets. Hopefully, we would be able to train the system beyond needing to use our own creator-generated values.

### Example 1:
![Screenshot](https://github.com/TungPhung/Twitter-Natural-Disaster-Mapping/blob/master/images/Screen%20Shot%202019-04-26%20at%207.39.42%20AM.png)

### Example 2:
![Screenshot](https://github.com/TungPhung/Twitter-Natural-Disaster-Mapping/blob/master/images/Screen%20Shot%202019-04-26%20at%207.39.57%20AM.png)

### Example 3:
![Screenshot](https://github.com/TungPhung/Twitter-Natural-Disaster-Mapping/blob/master/images/Screen%20Shot%202019-04-26%20at%207.40.29%20AM.png)


## Sources

https://www.geeksonsite.com/computer-security/what-does-virus-scan-do-how-antivirus-software-works/





